{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoang Dieu Linh\n",
    "# ID: 11202127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/10000], Loss: 0.24980191886425018\n",
      "Epoch [2000/10000], Loss: 0.24951764941215515\n",
      "Epoch [3000/10000], Loss: 0.24890929460525513\n",
      "Epoch [4000/10000], Loss: 0.24737311899662018\n",
      "Epoch [5000/10000], Loss: 0.24324986338615417\n",
      "Epoch [6000/10000], Loss: 0.23293232917785645\n",
      "Epoch [7000/10000], Loss: 0.2142535150051117\n",
      "Epoch [8000/10000], Loss: 0.19575709104537964\n",
      "Epoch [9000/10000], Loss: 0.18081042170524597\n",
      "Epoch [10000/10000], Loss: 0.1628636121749878\n",
      "Accuracy: 75.00%\n",
      "Hidden layer weights:\n",
      "Parameter containing:\n",
      "tensor([[-1.0561, -0.9370],\n",
      "        [ 4.2818,  4.2674]], requires_grad=True)\n",
      "Output layer weights:\n",
      "Parameter containing:\n",
      "tensor([[1.4529, 3.4050]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Input and target data for the XOR problem\n",
    "inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "targets = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Define the neural network\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 2)  # Input layer\n",
    "        self.layer2 = nn.Linear(2, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer1(x))  # Sigmoid activation for the hidden layer\n",
    "        x = torch.sigmoid(self.layer2(x))  # Sigmoid activation for the output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model and optimization\n",
    "model = XORModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the model's predicted outputs\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Clear gradients and backpropagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predicted = model(inputs)\n",
    "    predicted = (predicted > 0.5).float()  # Convert outputs to 0 or 1 based on a threshold of 0.5\n",
    "    accuracy = (predicted == targets).sum().item() / len(targets)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print the learned weights\n",
    "print(\"Hidden layer weights:\")\n",
    "print(model.layer1.weight)\n",
    "print(\"Output layer weights:\")\n",
    "print(model.layer2.weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Loss: 0.3844\n",
      "Epoch [2/5] Loss: 0.1862\n",
      "Epoch [3/5] Loss: 0.1404\n",
      "Epoch [4/5] Loss: 0.1132\n",
      "Epoch [5/5] Loss: 0.0960\n",
      "Finished Training\n",
      "Accuracy on the test dataset: 96.88%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations to apply to the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Define batch size for training and testing\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the neural network\n",
    "net = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss / (i+1):.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test the model on the test dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on the test dataset: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] Loss: 3.0665\n",
      "Epoch [2/5] Loss: 2.3100\n",
      "Epoch [3/5] Loss: 2.3092\n",
      "Epoch [4/5] Loss: 2.3101\n",
      "Epoch [5/5] Loss: 2.3102\n",
      "Epoch [1/5] Loss: 0.3941\n",
      "Epoch [2/5] Loss: 0.2760\n",
      "Epoch [3/5] Loss: 0.2448\n",
      "Epoch [4/5] Loss: 0.2525\n",
      "Epoch [5/5] Loss: 0.2305\n",
      "Epoch [1/5] Loss: 0.3925\n",
      "Epoch [2/5] Loss: 0.1943\n",
      "Epoch [3/5] Loss: 0.1439\n",
      "Epoch [4/5] Loss: 0.1138\n",
      "Epoch [5/5] Loss: 0.0972\n",
      "Epoch [1/5] Loss: 0.7827\n",
      "Epoch [2/5] Loss: 0.3452\n",
      "Epoch [3/5] Loss: 0.2964\n",
      "Epoch [4/5] Loss: 0.2661\n",
      "Epoch [5/5] Loss: 0.2416\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABQ/0lEQVR4nO3de3gU5d3/8fd3N+eEAHIIgYAJJlLBAyIiHgkeEatU26ptn2Lbx2q1R6tWWvp4aH+tPj1gS6W1am31qYpaUSwiFNGIh3pAi1ZQCgJKADlDCCQh2b1/f+wmbDabZAPZTLL7eV3XXtmduWfm/u4k7Id7ZmfMOYeIiIiIdC2f1x0QERERSUUKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTCRTmZmz5rZFZ3dNpmY2TAzqzYzfxttnJmVduI2TzezlRGvR5jZv8xsj5l9x8yyzezvZrbbzB7vrO0mm/B+G+51P0SSgUKYCE0fLI2PoJnVRLz+UkfW5Zw73zn3QGe37QgzKzezys5eb2dxzn3snMtzzgUAzKzCzK482PWZ2a1mVh8OVHvM7D9mdpeZFUZs8yXn3IiIxX4AVDjnejnnZgKfAwqAfs65zx9sXw6y/+3uLzP7i5n9v67qU2vC+21NZ683Yh9Wm9kuM3vVzE7uwPKdGtpFuoJCmAhNHyx5zrk84GPgwohpDzW2M7M073op7XjUOdcLOAy4GBgEvBUZxKIcDiyPev0f51xDRzecLL8X3aCOR8N/g/2BFwCNSEpSUwgTaUPjCIWZ3WRmnwB/NrO+ZjbPzLaa2c7w86KIZZpGdczsK2b2spn9Ktx2rZmdf5BtS8xsSXik5zkzm2Vmfz2Imo4Kb3eXmS03s4si5k02sxXhbWwwsxvC0/uH69xlZjvM7CUza/Hvh5ndZma/Cz9PN7O9ZvaL8OtsM6sNv3/F4ZGLNDP7GXA6cFd4FOSuiFWebWarwu/HLDOz9upzztU755YDlwFbgevD228abTKz54GJEdt8BLgZuCz8+r/D7b5mZu+Ht7/QzA6PqNWZ2TfNbBWwKjzt02a2LGIk59iI9uvM7AYze9dChzwfNbMsM8sFngUG24HR18Ht7sjm73tb251mZh+G9+kKM7s4Yt5XzOwVM7vTzHYAt1poxG2WmT0TXuZ1Mzsiqu7S8PP22p5rZivD9f7ezF60OEY8w0H4IWCImQ0Ir2ucmf0zXOMmC410ZoTnLQkv+k74/bssjvflpvDv+J5wH8/qyHsu0hkUwkTaN4jQ6MrhwFWE/m7+HH49DKgB7mp1aTgJWEnof/e/AP7URphoq+3DwBtAP+BW4MsdLcTM0oG/A/8ABgLfBh4ys8bDdH8Crg6PKB0NPB+efj1QCQwgdMjuR0Cse569CJSHn58IfAJMCL8+GVjpnNsZuYBzbjrwEvCt8MjjtyJmfzq8nuOAS4Hz4q01fKhzLqGAFz3vzKhtfgH4OeGRGOfcn8zsM+E6LwnX/RLwSNSqPkNon400szHA/cDVhPbRH4GnzSwzov2lwCSgBDgW+Ipzbi9wPrAxYvR1Y7x1xrHdD8PvQW/gNuCv1nx08CRgDaHfh5+Fp30h3LYvsDpieiwx25pZf+BvwA/D/VoJnBJnTRnAVGA70Pj7EgCuI/S3cTJwFnAtgHPujHCb48Lv36NtvS/h3/dvASeGf9fPA9bF0zeRzqQQJtK+IHCLc67OOVfjnNvunHvCObfPObeH0IfOhDaW/8g5d284FDwAFBIKMnG3NbNhhMLIzc65/c65l4GnD6KW8UAecEd4Pc8D8wh9kALUEwoU+c65nc65tyOmFwKHh0eaXnKxbzz7T6DMzPoBZxAKdUPMLI/Qe/RiB/t7h3Nul3PuY0KHp0Z3cPmNhAL0wbgauN059354ZObnwOjI0bDw/B3OuRrg68AfnXOvO+cC4XP96gi9541mOuc2Oud2EArDHa0nlja365x7PLzNoHPuUUKjduMilt/onPudc64hXAfAHOfcGxEjUm31s7W2k4Hlzrk54XkzCYXytlxqZrsI/cfm68DnGg8PO+fecs69Fu7nOkKhqq2/u7belwCQSeh3Pd05t84592E7fRPpdAphIu3b6pyrbXxhZjlm9kcz+8jMqoAlQB9r/Zt+TR88zrl94ad5HWw7GNgRMQ1gfQfrILye9c65YMS0j4Ah4eefJfTh+VH40FHjidG/JDTK8Q8zW2Nm02KtPPwhvpTQh+MZhELXq8CpHFwIi/zQ3kfr71trhgA7OrhMo8OB34YPZe0Kr8c48F5B831wOHB9Y/vwMkMJveeNDrWe1vrZ6nbNbGrEIbldhEY4+7dSw8H0s7W2gyPXHQ7t7X1Z5DHnXB9C/0l5DzihcYaZHWmhQ+KfhP/ufh5VR7RW3xfn3Grge4RGlLeY2eyOHgIW6QwKYSLtix7xuR4YAZzknMsnFDYg9AGdKJuAw8wsJ2La0INYz0ZgqDU/n2sYsAHAOfemc24KoUNTTwGPhafvcc5d75wbDlwIfL+Nc2heBM4EjgfeDL8+j9Doy5JWlok1qnZIwjVeSOgw4sFYT+jQbJ+IR7Zz7tWINi6q/c+i2uc456IPYcZyKPW3ut3wqN29hA699QsHnPdo/rva6e992CYg8lxJi3zdFufcNkIjkbdGHDr9A/ABUBb+u/sRbf/Ntbk/nHMPO+dOIxTWHPC/HStP5NAphIl0XC9Ch0t2mdlhwC2J3qBz7iNCI0y3mllGeITqwvaWs9CJ300PQueU7QV+YKET58vD65kdXu+XzKy3c64eqCJ02KbxBOfS8Adp4/RAK5t9kdD5PCucc/uBCuBKYK1zbmsry2wGOuXaU+G6jiJ0/tYgYMZBrupu4IdmNiq83t5m1talK+4FvmFmJ1lIrpldYGa94tjWZqCfmfVup50/ap9mtLPdXEIBY2u4hq8SGgnrCs8Ax5jZZyz0rctvEtofcXHOfQAsJHQpEQj93VUB1Wb2KeCaqEWif4dafV8sdI24M8PnzdUS+ntu7fdZJGEUwkQ67jdANrANeA1Y0EXb/RKhE5K3A/8PeJTQOS6tGULowyXyMRS4iNCJ4NuA3wNTwx94EDrZf134cM83gP8KTy8DngOqCZ339XvnXEUr232V0PvTOOq1gtAHXWujYAC/BT5noW8hzmyjXVsuM7NqYBeh8+W2Ayd05CT3SM65JwmNjswOvx/vEXrfWmu/lNB5SHcROpl8NfCVOLf1AaHQuCZ86Ky1Q2PTaL4/n29ru865FcCvCe2zzcAxwCvx9OlQhUezPk/oCybbgZGE/iPR1u9stF8CV5nZQOAG4IvAHkIB69GotrcCD4Tfv0vb2R+ZwB2E/gY+ITTy+6OOVShy6Cz2ubUi0t2Z2aPAB865hI/EiRyq8OHhSuBLzrkXvO6PSHegkTCRHsLMTjSzI8zMZ2aTgCmEztsS6ZbM7Dwz6xM+7Nd4DtdrHndLpNvw+urIIhK/QcAcQtc8qgSucc79y9suibTpZELXt8sgdFj6MxGXwRBJeTocKSIiIuIBHY4UERER8YBCmIiIiIgHetw5Yf3793fFxcUJ387evXvJzc1N+Ha6I9WemrVDatefyrVDatev2lOzduia+t96661tzrkBseb1uBBWXFzM0qVLE76diooKysvLE76d7ki1l3vdDc+kcv2pXDukdv2qvdzrbnimK+o3s49am6fDkSIiIiIeUAgTERER8YBCmIiIiIgHetw5YSIiIhKf+vp6Kisrqa2tjTm/d+/evP/++13cq+6jM+vPysqiqKiI9PT0uJdRCBMREUlSlZWV9OrVi+LiYsysxfw9e/bQq1cvD3rWPXRW/c45tm/fTmVlJSUlJXEvp8ORIiIiSaq2tpZ+/frFDGDSecyMfv36tTri2BqFMBERkSSmANY1DuZ9VggTERGRhMnLy2sx7dZbb2XIkCGMHj2akSNH8sgjj3RonbfffjulpaWMGDGChQsXxmzz+OOPM2rUKHw+X5dcX/RgKISJiIhIl7vuuutYtmwZc+fO5eqrr6a+vj6u5VasWMHs2bNZvnw5CxYs4NprryUQCLRod/TRRzNnzhzOOOOMzu56p1EIExEREc+UlZWRk5PDzp0742o/d+5cLr/8cjIzMykpKaG0tJQ33nijRbujjjqKESNGdHZ3O5W+HSkiIpICbvv7clZsrGo2LRAI4Pf7D3qdIwfnc8uFow6pX2+//TZlZWUMHDgQgF/+8pc89NBDLdqdccYZzJw5kw0bNjB+/Pim6UVFRWzYsOGQ+uAVhbAozjn+/u4mcoLO666IiIgkrTvvvJN7772XNWvWsGDBgqbpN954IzfeeGOryznX8vO5p375QCEsyutrd/CdR/7F4FwjZ9g2Tint73WXREREDlmsESsvrxN23XXXccMNNzBnzhymTp3Khx9+SFZWVrsjYUVFRaxfv75pemVlJYMHD+7KrncanRMW5aSSw7hv6ljqg/DF+17nmw+/zcZdNV53S0REJCldcskljB07lgceeAAIjYQtW7asxWPmzJkAXHTRRcyePZu6ujrWrl3LqlWrGDdunJclHDSFsChmxtkjC/jZadlcd/aRPLdiM2f9+kV+X7GauoaW374QERGR1u3bt4+ioqKmx4wZM1q0ufnmm5kxYwbBYLDd9Y0aNYpLL72UkSNHMmnSJGbNmtV0XtuVV17ZdDmKJ598kqKiIv75z39ywQUXcN5553VuYZ1AhyNbkeE3vltexiVjhvDTeSv4xYKV/G1pJbdcNIoJRw7wunsiIiI9QjzB6oQTTmDlypVxr3P69OlMnz69xfT77ruv6fnFF1/MxRdfHPc6vZCwkTAzyzKzN8zsHTNbbma3xWhjZjbTzFab2btmNiZR/TlYQw/L4Z6pY/nLV0/EAVfc/wZXPbiU9Tv2ed01ERER6cESeTiyDjjTOXccMBqYZGbjo9qcD5SFH1cBf0hgfw5J+YiBLPje6dx43gheWrWNs2e8yG+fW0VtvQ5RioiISMclLIS5kOrwy/TwI/p7pVOAB8NtXwP6mFlhovp0qDLT/HxzYimLr5/A2SMLuPO5/3DunUt4bsVmr7smIiIiPYzFut5Gp63czA+8BZQCs5xzN0XNnwfc4Zx7Ofx6MXCTc25pVLurCI2UUVBQcMLs2bMT1udG1dXVMe93FWnF9gB/XVHHxr2O4wb4+dJRGQzM6fnfdYin9mSVyrVDatefyrVDatefzLX37t2b0tLSVucf6sVae7rOrn/16tXs3r272bSJEye+5ZwbG6t9Qk/Md84FgNFm1gd40syOds69F9Ek1tXVWqRC59w9wD0AY8eOdeXl5QnobXMVFRW0t51y4MopQR54dR2/ee4//PiVOq6eMJxry0vJzui5v9Tx1J6sUrl2SO36U7l2SO36k7n2999/v83rgHl5nbDuoLPrz8rK4vjjj4+7fZcM2zjndgEVwKSoWZXA0IjXRcDGruhTZ8lI8/H1M4bz/A3lTD5mEL97fjVnz3iRBe9tinlVXxERERFI7LcjB4RHwDCzbOBs4IOoZk8DU8PfkhwP7HbObUpUnxKpID+L31x+PI9eNZ5eWWl8469vM/X+N/hwa3X7C4uIiCSpWId6b731VoYMGcLo0aMZOXIkjzzySIfWefvtt1NaWsqIESNYuHBhzDY7duzgnHPOoaysjHPOOafpBuHbt29n4sSJ5OXlcf3113e8oE6UyJGwQuAFM3sXeBNY5JybZ2bfMLNvhNvMB9YAq4F7gWsT2J8ucdLwfsz79mnccuFIln28i0m/WcIdz37A3roGr7smIiLSbVx33XUsW7aMuXPncvXVV1NfXx/XcitWrGD27NksX76cBQsWcO211xIItLxSwR133MFZZ53FqlWrOOuss7jjjjuA0CHDn/70p/zqV7/q1HoORiK/Hfmuc+5459yxzrmjnXM/CU+/2zl3d/i5c8590zl3hHPumOgT8nuqNL+Pr55awvM3lDNl9BDufvFDzvr1izz9zkYdohQREYlQVlZGTk5O00hVe+bOncvll19OZmYmJSUllJaW8sYbb8Rsd8UVVwBwxRVX8NRTTwGQm5vLaaedRlZWVqfVcLB0xfwEGtArk199/ji+MG4Ytzz9Ht955F88/PpH3HbR0YwYlLonQoqIiAeenQaf/LvZpOxAA/gPIQoMOgbOv+OQuvX2229TVlbGwIEDAdq9gfeGDRsYP/7AZUeLiorYsGFDi/abN2+msDB01avCwkK2bNlySP1MBIWwLnDC4X2Z+83TeOSNj/nlwpVMnvkSXzmlmO+eXUZ+VrrX3RMREelyd955J/feey9r1qxhwYIFTdNvvPFGbrzxxlaXi3VEySzWxRa6P4WwLuL3Gf81/nAmH1PILxeu5P5X1jJ32UZ+NPlTXHz8kB77CyQiIj1EjBGrGg8vUXHddddxww03MGfOHKZOncqHH35IVlZWuyNhRUVFrF+/vml6ZWUlgwcPbtG+oKCATZs2UVhYyKZNm5pG2rqTnn9l0R7msNwMbr/kGJ669lSG9M3m+4+9w+fv/ifLN+5uf2EREZEkc8kllzB27FgeeOABIDQStmzZshaPmTNnAnDRRRcxe/Zs6urqWLt2LatWrWLcuHEt1nvRRRc1rfOBBx5gypQpXVdUnBTCPHLc0D48ec0p/O9nj2HNtr1c+LuXuXnue+zeF9+3Q0RERHqCffv2UVRU1PSYMWNGizY333wzM2bMIBgMtru+UaNGcemllzJy5EgmTZrErFmzmq56f+WVV7J0aeg7ftOmTWPRokWUlZWxaNEipk2b1rSO4uJivv/97/Pwww9TVFTEihUrOqnajtHhSA/5fMZlJw5j0qhCZixayf+99hHz3t3ETZNG8PkThuLz6RCliIj0bPEEqxNOOIGVK1fGvc7p06czffr0FtPvu+++puf9+vVj8eLFMZdft24d4P0dAzQS1g30zknntilH8/dvn8bw/rnc9MS/ufgPr/Ju5S6vuyYiIiIJohDWjYwa3JvHv3EyMy49jg07a5gy6xV+OOff7Ni73+uuiYiISCdTCOtmzIxLxhTx/A0T+NqpJTy2dD1n/rqCv772EYGgLvQqIiKSLBTCuqn8rHT+59Mjefa7p/OpQb348VPvMWXWy7z1UXxXFBYREZHuTSGsmzuyoBePfH08v/vC8Wzbs5/P/uFVbnz8HbZV13ndNRERETkECmE9gJlx4XGDWXz9BK6eMJynlm1g4q8q+PMra2kItP+tExEREel+FMJ6kNzMNH54/lE8+90zGD20D7f9fQWf/t3LvL5mu9ddExERiSkvL6/FtFtvvZUhQ4YwevRoRo4cySOPPNKhdd5+++2UlpYyYsQIFi5cGLPNjh07OOeccygrK+Occ85pdoPwxuXHjBnTbPnp06czdOjQmH1OBIWwHqh0YB4Pfm0cd//XGPbUNnDZPa/xvdn/YnNVrdddExERict1113HsmXLmDt3LldffTX19fFdrHzFihXMnj2b5cuXs2DBAq699loCgUCLdnfccQdnnXUWq1at4qyzzuKOO+5osfycOXOaLX/hhRfyxhtvdF6R7VAI66HMjElHF/Lc9yfw7TNLmf/vTzjzVxXcu2QN9TpEKSIiPURZWRk5OTnNRqraMnfuXC6//HIyMzMpKSmhtLQ0ZnCaO3cuV1xxBQBXXHEFTz31VIvli4uLmy0/fvx4CgsLO6ewOOiK+T1cdoaf688dwWfHFPGTeSv42fz3eXTpem67aBSnlvb3unsiItJN/O8b/8sHOz5oNi0QCDTd8udgfOqwT3HTuJsOqV9vv/02ZWVlTTfYbu8G3hs2bGD8+PFN04uKitiwYUOL9ps3b24KVIWFhWzZsgUg7uW7gkJYkijun8v9XzmR51Zs5rZ5y/nSfa9zwTGFTL/gKAb3yfa6eyIiIs3ceeed3HvvvaxZs4YFCxY0Tb/xxhu58cYbW13OuZbXzDSL/zZ/h7p8Z1IISzJnjyzgtLL+3LNkDbNeWM3zH2zhW2eWcuXpJWSmHfz/dkREpGeLNWLl5b0Tr7vuOm644QbmzJnD1KlT+fDDD8nKymp3JKyoqIj169c3Ta+srGTw4MEt2hcUFLBp0yYKCwvZtGlT00hbvMt3BZ0TloSy0v1856wynvv+BM44sj+/XLiSSb95iYqVW7zumoiISDOXXHIJY8eO5YEHHgBCI2HLli1r8Zg5cyYAF110EbNnz6auro61a9eyatUqxo0b12K9F110UdM6H3jgAaZMmdJi+XXr1rW6fFdQCEtiQw/L4Y9fHssDXwv9cn3lz29y1YNLWb9jn8c9ExGRVLFv3z6KioqaHjNmzGjR5uabb2bGjBkEg+1/sWzUqFFceumljBw5kkmTJjFr1qym89quvPJKli5dCsC0adNYtGgRZWVlLFq0iGnTprVY/pJLLmm2/A9+8AOKioqa+nzrrbd20rsQmw5HpoAJRw5gwfdO508vr+V3i1dz9owXuba8lKsnDCcrXYcoRUQkceIJVieccAIrV66Me53Tp09n+vTpLabfd999Tc/79evH4sWL21w++nDsL37xC37xi1/E3Y9DpZGwFJGZ5ufa8lIWXz+Bs0cWcOdz/+GcO1/kuRWbve6aiIhISlIISzGD+2Qz64tjePjKk8hK83Plg0v52l/eZN22vV53TUREJKUohKWoU0r7M/+7p/PjC47ijbU7OPfOJfxq4Upq9re86rCIiIh0PoWwFJbu93Hl6cN5/voJXHBsIXe9EDpf7M1PGmJeR0VEREQ6j0KYMDA/izsvG81jV59Mr6w0Zi2rY+r9b7B6S7XXXRMREUlaCmHSZFzJYcz79ml86agMlq3fxfm/XcLtz75PdV2D110TERFJOgph0kya38c5h6fzwg3lfGb0EP744hrO+nUFT7+zUYcoRUSkw/Ly8lpMu/XWWxkyZAijR49m5MiRPPLIIx1a5+23305paSkjRoxg4cKFMdvs2LGDc845h7KyMs4555xmNwhvXH7MmDHNln/rrbc45phjKC0t5Tvf+U7T596SJUsYM2YMaWlp/O1vf+tQX9uiECYx9c/L5JefP445157CgF6ZfOeRf/GFe19j5Sd7vO6aiIgkgeuuu45ly5Yxd+5crr76aurr6+NabsWKFcyePZvly5ezYMECrr32WgKBll8qu+OOOzjrrLNYtWoVZ511FnfccUeL5efMmdNs+WuuuYZ77rmHVatWsWrVqqZ7Wg4bNoy//OUvfPGLX+yk6kMUwqRNY4b1Ze43T+NnFx/NB5/sYfLMl/jpvBVU1cb3xyIiItKWsrIycnJymo1UtWXu3LlcfvnlZGZmUlJSQmlpKW+88UbMdldccQUAV1xxBU899VSL5YuLi5uW37RpE1VVVZx88smYGVOnTm1apri4mGOPPRafr3Njk66YL+3y+4wvnXQ4k48u5Jf/WMn9r6xl7rKN/PD8T3HJmCGe3X1eRETi98nPf07d+x80m9YQCLDDf/B3Tsk86lMM+tGPDqlfb7/9NmVlZU032G7vBt4bNmxg/PjxTdOLiorYsGFDi/abN2+msLAQgMLCQrZsCd0/ubXl09PTKSoqane9nUkhTOLWNzeDn198DJefOJSb5y7n+sff4ZE3Pua2KaMYNbi3190TEZEe5M477+Tee+9lzZo1TYf9IHQD7xtvvLHV5WKdn9yRwYDWlj/U9R4MhTDpsGOL+jDnmlP421uV3LHgAy783cv81/jDuf6cEfTOSfe6eyIiEkOsEavoeyd2peuuu44bbriBOXPmMHXqVD788EOysrLaHQkrKipi/fr1TdMrKysZPHhwi/YFBQVs2rSJwsJCNm3a1DTS1tryRUVFVFZWtrvezqRzwuSg+HzGpScO5YXry/ny+MP562sfMfHXFTz65scEg/oWpYiIxOeSSy5h7NixPPDAA0BoJGzZsmUtHjNnzgTgoosuYvbs2dTV1bF27VpWrVrFuHHjWqz3oosualrnAw88wJQpU1osv27duqblCwsL6dWrF6+99hrOOR588MGmZRJFIUwOSe+cdG6bcjTzvn06RwzI5aYn/s3Ff3iVdyt3ed01ERHpBvbt20dRUVHTY8aMGS3a3HzzzcyYMYNgMNju+kaNGsWll17KyJEjmTRpErNmzcIfPq/tyiuvZOnSpQBMmzaNRYsWUVZWxqJFi5g2bVqL5S+55JJmy//hD3/gyiuvpLS0lCOOOILzzz8fgDfffJOioiIef/xxrr76akaNGtUp740OR0qnGDk4n8euPpmnlm3g5/M/YMqsV7j8xKHceN6nOCw3w+vuiYiIR+IJVieccAIrV66Me53Tp09n+vTpLabfd999Tc/79evH4sWL21w++nDs2LFjee+991q0P/HEE5sdquwsGgmTTmNmXHx8Ec9fP4H/PrWEx5ZWMvFXFfzfax8R0CFKERGRZhTCpNP1ykrnx58eybPfPZ2Rhfn8z1PvMWXWy7z1UXzXgBEREUkFCmGSMEcW9OLhr5/E775wPNv27Oezf3iVGx5/h6176rzumoiIiOcUwiShzIwLjxvM4usncE35EcxdtoEzf13Bn19ZS0Og/fMERETk0Oi+v13jYN5nhTDpErmZadw06VMs+N4ZjB7ah9v+voJP/+5lXl+z3euuiYgkraysLLZv364glmDOObZv305WVlaHlkvYtyPNbCjwIDAICAL3OOd+G9WmHJgLrA1PmuOc+0mi+iTeO2JAHg9+bRwLl2/mp/NWcNk9r/GZ0YP54eSjKMjv2C+viIi0rfECpFu3bo05v7a2tsPBIZl0Zv1ZWVnNbnsUj0ReoqIBuN4597aZ9QLeMrNFzrkVUe1ecs59OoH9kG7GzJh09CAmHDmAP1Ss5u4la1i0YjPfPbuMr55aQrpfA7QiIp0hPT2dkpKSVudXVFRw/PHHd2GPuhev60/Yp51zbpNz7u3w8z3A+8CQRG1Pep7sDD/fP3cEi647g/HD+/Hz+R9w/m9f4pXV27zumoiISMJZVxwnNrNiYAlwtHOuKmJ6OfAEUAlsBG5wzi2PsfxVwFUABQUFJ8yePTvhfa6uriYvLy/h2+mOvKp92ZYGHnp/P1trHCcO8nP5iAz6ZXftqFgq73dI7fpTuXZI7fpVe2rWDl1T/8SJE99yzo2NNS/hIczM8oAXgZ855+ZEzcsHgs65ajObDPzWOVfW1vrGjh3rGm9JkEgVFRWUl5cnfDvdkZe119YHuGfJGma9sBqfGd86s5QrTy8hM83fJdtP5f0OqV1/KtcOqV2/ai/3uhue6Yr6zazVEJbQYQYzSyc00vVQdAADcM5VOeeqw8/nA+lm1j+RfZLuLSvdz3fOKuO570/gjCP788uFK5n0m5eoWLnF666JiIh0qoSFMDMz4E/A+865lnfrDLUZFG6HmY0L90fXLBCGHpbDH788lge+Ng4DvvLnN/n6g0tZv2Of110TERHpFIkcCTsV+DJwppktCz8mm9k3zOwb4TafA94zs3eAmcDlThczkQgTjhzAgu+dwU2TPsUrq7dx9owX+c1z/6G2PuB110RERA5Jwi5R4Zx7GbB22twF3JWoPkhyyEjzcU35EXzm+MH87Jn3+c1zq3ji7Upu/vQozj5qIOHBVBERkR5FF2SSHqOwdzZ3fXEMD195Ellpfr7+4FK+9pc3Wbdtr9ddExER6TCFMOlxTintz/zvns6PLziKN9ft5Nw7l/CrhSvZt7/B666JiIjETSFMeqR0v48rTx/O89dP4NPHFnLXC6s5+9cv8uy/N+keaSIi0iMohEmPNjA/ixmXjebxb5xMfnY61zz0NlPvf4PVW6q97pqIiEibFMIkKZxYfBjzvn0at100imXrdzHpN0u4ff77VNfpEKWIiHRPCmGSNNL8Pq44pZgXbijnkjFD+OOSNZz16wrmLtugQ5QiItLtKIRJ0umfl8kvPnccT157CgN7ZfHd2cu4/J7XWPnJHq+7JiIi0kQhTJLW8cP68tQ3T+VnFx/Nys17mDzzJX7y9xVU1dZ73TURERGFMElufp/xpZMO54Xry7nsxKH8+dW1nPmrF3nirUqCQR2iFBER7yiESUrom5vBzy8+hqe/eRpFfbO5/vF3+Pwf/8nyjbu97pqIiKQohTBJKccU9WbONafwi88dy7pte7nwdy/zP0+9x+59OkQpIiJdK2H3jhTprnw+49KxQzlv1CDuXPQfHvznOp759yZ+cN4IBupblCIi0kUUwiRl9c5O59aLRnHp2KHc8vR7TJvzbwbnGsWrX2t1mdbuFW5t3Kv+YO4v3tZNydtaXev9i29b27fX8uC6N9tdru2aOv5eHExNoeViz2xzmVbmbdlSy2Mb3mo2rbVMHmu6I3bj2G3jX29rrTu23pZzoqfs2F7LX9a+ccjrbc0hv2et7YsY62i9bWy7dtXw+w/+2crc7qO19+tQ7N5dw6wPXu309faU/88ekVVPebl321cIk5Q3cnA+j119Mk8t28A9i/5NQyDWB1br/6J09B/8tj64Ovbh3Hr7thZqaxt76hzBPXUxlon/w7Kt6W1vv+P/anfkg7mt9gB79wbZ7VreaaEjwbsjgbu1oB1raqt9iDG9I8E0ctKeeoft3d9q444E8tbbHup640/xMd/HVtbrs9CXeLo/O6j/1LXFb6HbwCVCZ/c1Efwe91EhTITQh8PFxxfRd/dqystP9ro7nqmoqKC8/DSvu+GJUO0TvO6GZ7Tvx3vdDU+kcu0Qqt9LOjFfRERExAMKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTARERERDyiEiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ8oBAmIiIi4gGFMBEREREPKISJiIiIeEAhTERERMQDCmEiIiIiHlAIExEREfGAQpiIiIiIBxTCRERERDygECYiIiLiAYUwEREREQ8ohImIiIh4QCFMRERExAMKYSIiIiIeSFgIM7OhZvaCmb1vZsvN7Lsx2piZzTSz1Wb2rpmNSVR/RERERLqTtASuuwG43jn3tpn1At4ys0XOuRURbc4HysKPk4A/hH+KiIiIJLWEjYQ55zY5594OP98DvA8MiWo2BXjQhbwG9DGzwkT1SURERKS7MOdc4jdiVgwsAY52zlVFTJ8H3OGcezn8ejFwk3NuadTyVwFXARQUFJwwe/bshPe5urqavLy8hG+nO1LtqVk7pHb9qVw7pHb9qj01a4euqX/ixIlvOefGxpqXyMORAJhZHvAE8L3IANY4O8YiLVKhc+4e4B6AsWPHuvLy8s7uZgsVFRV0xXa6I9Ve7nU3PJPK9ady7ZDa9av2cq+74Rmv60/otyPNLJ1QAHvIOTcnRpNKYGjE6yJgYyL7JCIiItIdJPLbkQb8CXjfOTejlWZPA1PD35IcD+x2zm1KVJ9EREREuotEHo48Ffgy8G8zWxae9iNgGIBz7m5gPjAZWA3sA76awP6IiIiIdBsJC2Hhk+1jnfMV2cYB30xUH0RERES6K10xX0RERMQDCmEiIiIiHlAIExEREfGAQpiIiIiIBxTCRERERDygECYiIiLiAYUwEREREQ8ohImIiIh4QCFMRERExAMKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTARERERDyiEiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ8oBAmIiIi4gGFMBEREREPKISJiIiIeEAhTERERMQDCmEiIiIiHlAIExEREfFAXCHMzHLNzBd+fqSZXWRm6YntmoiIiEjyinckbAmQZWZDgMXAV4G/JKpTIiIiIsku3hBmzrl9wCXA75xzFwMjE9ctERERkeQWdwgzs5OBLwHPhKelJaZLIiIiIskv3hD2PeCHwJPOueVmNhx4IWG9EhEREUlycY1mOedeBF4ECJ+gv805951EdkxEREQkmcX77ciHzSzfzHKBFcBKM7sxsV0TERERSV7xHo4c6ZyrAj4DzAeGAV9OVKdEREREkl28ISw9fF2wzwBznXP1gEtYr0RERESSXLwh7I/AOiAXWGJmhwNVieqUiIiISLKL98T8mcDMiEkfmdnExHRJREREJPnFe2J+bzObYWZLw49fExoVExEREZGDEO/hyPuBPcCl4UcV8OdEdUpEREQk2cUbwo5wzt3inFsTftwGDG9rATO738y2mNl7rcwvN7PdZrYs/Li5o50XERER6aniDWE1ZnZa4wszOxWoaWeZvwCT2mnzknNudPjxkzj7IiIiItLjxXv/x28AD5pZ7/DrncAVbS3gnFtiZsWH0DcRERGRpBXXSJhz7h3n3HHAscCxzrnjgTM7Yfsnm9k7ZvasmY3qhPWJiIiI9Ajm3MFdc9XMPnbODWunTTEwzzl3dIx5+UDQOVdtZpOB3zrnylpZz1XAVQAFBQUnzJ49+6D63BHV1dXk5eUlfDvdkWpPzdohtetP5dohtetX7alZO3RN/RMnTnzLOTc21rxDCWHrnXND22lTTCshLEbbdcBY59y2ttqNHTvWLV26tCNdPSgVFRWUl5cnfDvdkWov97obnknl+lO5dkjt+lV7udfd8ExX1G9mrYaweE/Mj+WQbltkZoPMzMLPx4X7sv1Q1ikiIiLSU7R5Yr6Z7SF22DIgu51lHwHKgf5mVgncAqQDOOfuBj4HXGNmDYS+aXm5O9hhOREREZEeps0Q5pzrdbArds59oZ35dwF3Hez6RURERHqyQzkcKSIiIiIHSSFMRERExAMKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTARERERDyiEiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ8oBAmIiIi4gGFMBEREREPKISJiIiIeEAhTERERMQDCmEiIiIiHlAIExEREfGAQpiIiIiIBxTCRERERDygECYiIiLiAYUwEREREQ8ohImIiIh4QCFMRERExAMKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTARERERDyiEiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ8oBAmIiIi4gGFMBEREREPKISJiIiIeCBhIczM7jezLWb2XivzzcxmmtlqM3vXzMYkqi8iIiIi3U0iR8L+AkxqY/75QFn4cRXwhwT2RURERKRbSVgIc84tAXa00WQK8KALeQ3oY2aFieqPiIiISHfi5TlhQ4D1Ea8rw9NEREREkp455xK3crNiYJ5z7ugY854BbnfOvRx+vRj4gXPurRhtryJ0yJKCgoITZs+enbA+N6quriYvLy/h2+mOVHtq1g6pXX8q1w6pXb9qT83aoWvqnzhx4lvOubGx5qUldMttqwSGRrwuAjbGauicuwe4B2Ds2LGuvLw84Z2rqKigK7bTHan2cq+74ZlUrj+Va4fUrl+1l3vdDc94Xb+XhyOfBqaGvyU5HtjtnNvkYX9EREREukzCRsLM7BGgHOhvZpXALUA6gHPubmA+MBlYDewDvpqovoiIiIh0NwkLYc65L7Qz3wHfTNT2RURERLozXTFfRERExAMKYSIiIiIeUAgTERER8YBCmIiIiIgHFMJEREREPKAQJiIiIuIBhTARERERDyiEiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ8oBAmIiIi4gGFMBEREREPpHndge7GOcfeV16FQMDrroiIiEgSUwiLUrNsGeuvvJIBublsmjyZ/AsuIOfEsZjf73XXREREJInocGSU7FGjKPrD76kbOZLdzzzDx1/5CqvKy/nkZz9n37/+hXPO6y6KiIhIEtBIWBTLyKDXxIlUmTH6pJOofvFFqp6Zz65HH2Xn//0f6YMHk3/BZPInTybzU5/CzLzusoiIiPRACmFt8GVnkz9pEvmTJhGorqZ68WJ2P/MM2//8F7bfex8ZJSXkT55M/gWTyRw+3OvuioiISA+iEBYnf14evadMofeUKTTs3Mmefyyiav58tv3+92ybNYvMo44if/L55J8/mYyiIV53V0RERLo5hbCDkNa3L30vu5S+l11K/eYt7Fm4gKpn5rP11zPY+usZZB93HPkXTKbXeZNILxjodXdFRESkG9KJ+YcovWAgh02dSvGjszniuUUMuP77BPfvZ/PPb2d1eTkfXfEVdj76GA07d3rdVREREelGFMI6UUZREf2//nWGPzmH4c/Mo/+119KweTOf3HILq04/g4+vuopdTz1FoLra666KiIiIxxTCEiTziCMY8O1vMfzZ+ZQ8OYd+X/0K+1d/yKZpP2TVKadS+e3vULVgAcGaGq+7KiIiIh7QOWEJZmZkHXUUWUcdxYDvf5/ad95h9zPzqVrwLHsWLcJycuh15pnkXzCZvFNPxTIyvO6yiIiIdAGFsC5kZmSPHk326NEUTLuJfW8upWr+fPYsXEjVvHn48vPpde459J48mZxx47A07R4REZFkpU95j5jfT+74k8gdfxKD/ufH7H311VAge3YBu//2BP5+/cg/7zzyL5hM9vHHYz4dORYREUkmCmHdgKWnkzdhAnkTJhCsraV6yRKq5j/LrieeYOfDD5NWWEj++eeTP3kyWaNG6ir9IiIiSUAhrJvxZWWRf+655J97LoHqvVS/8DxVz8xnx//9Hzvuv5+Mww8/cNuk0lKvuysiIiIHSSGsG/Pn5dL7wgvpfeGFBHbtYs9zz4Wu0n/3H9n2+z+QeeSRodsmTT6fjGHDvO6uiIiIdIBCWA/h79OHPp/7HH0+9zkatm6lauE/qJo/n62/+Q1bf/Mbso49NnzbpPNJLyjwursiIiLSDp3t3QOlDRjAYf/1JYoffojS5xcz8MYboaGBLXf8L6vLJ/LRf32ZnY88QsOOHV53VURERFqhENbDpQ8eTL///holc55g+LPz6f/tb9Gwcyef3PaT0FX6r/w6u+Y8SaCqyuuuioiISASFsCSSWVLCgGuvZfi8v1Mydy79/vu/2b9uHZt+9CNWnXoa67/5LXY/8wzBffu87qqIiEjK0zlhScjMyBpxJFkjjmTAdd+j9t//puqZ+VQ9+yzVixdj2dn0mjiR/Asmk3v66fh0lX4REZEupxCW5MyM7GOPJfvYYxl40w/Yt7TxKv2hE/t9vXrR6+yzyZ88mdyTx+sq/SIiIl1En7gpxHw+cseNI3fcOAZNn87e114PBbJFi9j95JP4+/al16TzSB88GHfGGbpKv4iISAIphKUoS08n7/TTyDv9NIK33sLel16iav58dj/5FIfV1rL6rw+RP2kS+Z++gKyjj9ZV+kVERDqZQpjgy8yk19ln0+vsswnu3cvrv/89Res+YufDD7PjgQdIHzo0fFHYyWSNONLr7oqIiCQFhTBpxpebS92JJzL0xhsJVFWxZ1HoKv3b77uP7X/8I5llpaFAdv75ZBQXe91dERGRHiuhJ/2Y2SQzW2lmq81sWoz55Wa228yWhR83J7I/0jH+/Hz6fPYShv3pPsqWvMigW27G17s3W387kw8nnc/az36O7X+6n/qNG73uqoiISI+TsJEwM/MDs4BzgErgTTN72jm3IqrpS865TyeqH9I50vr1o+8XvkDfL3yB+k8+oerZBVTNn8+WX/6SLb/8JdljxoRuLH7eeaT17+91d0VERLq9RI6EjQNWO+fWOOf2A7OBKQncnnSR9EGD6PfVr1Dy+GMc8Y+FDPje9whWV7P5p/+PVWdM4OOvfY1df/sbgd27ve6qiIhIt5XIEDYEWB/xujI8LdrJZvaOmT1rZqMS2B9JgIxhw+j/jasZ/vRchv/9afpdfRX7N2xg04//h/+cdjrrr7mW3X+fR3DvXq+7KiIi0q2Ycy4xKzb7PHCec+7K8OsvA+Occ9+OaJMPBJ1z1WY2Gfitc64sxrquAq4CKCgoOGH27NkJ6XOk6upq8vLyEr6d7uiQa3eOtI8/JmvpUrKWvoV/505cejp1xxxD7YljqTv6aEhP77wOd6JU3u+Q2vWncu2Q2vWr9tSsHbqm/okTJ77lnBsba14iQ9jJwK3OufPCr38I4Jy7vY1l1gFjnXPbWmszduxYt3Tp0k7ubUsVFRWUl5cnfDvdUWfW7oJBav71r9BtkxYuJLB9O77c3NBV+i+YTO7JJ2PdKJCl8n6H1K4/lWuH1K5ftZd73Q3PdEX9ZtZqCEvkJSreBMrMrATYAFwOfDGqY4OAzc45Z2bjCB0e3Z7APkkXM5+PnBNOIOeEEyj40Q/Z+3rjVfqfY/fcufj79KHXueeSP3kyOSeOxfx+r7ssIiLSJRIWwpxzDWb2LWAh4Afud84tN7NvhOffDXwOuMbMGoAa4HKXqKE58ZylpZF36qnknXoqwVtuYe/Lr4Su0j9vHrsee4y0AQPodf4kek+eTNZxx+kq/SIiktQSerFW59x8YH7UtLsjnt8F3JXIPkj35MvIoNeZE+l15kSCNTVUv/giVc88w67Zj7Lzwf8jfcgQ8iefT/4FF5A5YoQCmYiIJB1dMV8858vODt2nctIkAnv2sGfx4tBV+u//M9vvvY+M4cObbpuUObzE6+6KiIh0CoUw6Vb8vXrR5zOfoc9nPkPDzp3sWfgPqubPZ9usWWy76y4yjzqK3heEbpuUPiTWFU9ERER6BoUw6bbS+val7+WX0ffyy6jfvIU9CxdQ9cx8tvzq12z51a/JHj2a/MmT6TXpPNIHDvS6uyIiIh2S0HtHinSW9IKBHDZ1KsWPzuaI5xYx4PvfJ1hby+af/5zV5RP56CtfZedjj9Gwc6fXXRUREYmLRsKi1O75hKVv/Ba31RFc68OXNwjyBkJWb9DJ4d1CRlER/a/6Ov2v+jp1H35I1fxnqXrmGT65+RY++clPyT31FHpPnkzeWWfhT+GLEIqISPemEBblw8pXuKZyHgCZFX+nuL6Bkvp6SgKOEn8eJZl9OTynkOxegyCvIBTQ8gogd+CB5xk5HleROjKPOIIB3/4W/b/1Terefz90yYv589l40zQsI4O8CRPIv+AC8son4MvK8rq7IiIiTRTCopQMP4+/5BzG80vnQe8G1u75mPdqtrCwvorQBcx2Qv1OBm99j5LKugMhLfzoHwhiGb3CgSwimMUKa7kDIC3D44qTg5mRNXIkWSNHMuD666lZtiw0QrbgWfYsWoQvJ4e8s84if/L55J16Kpah911ERLylEBYlJzOPEw6fyJ611uxWBnWBOj6q+oi1u9c2e7y9ey01gdqmdnmWTok/lxL8lNTvpWTHe5R8vISh1TuJeXOe7MOiwlo4sOVGTcs5DHy6mnw8zIyc448n5/jjKZh2E/vefDN026R//IOqv/8dX+/e5J97Tugq/ePG6Sr9IiLiCYWwOGX6Mzmy75Ec2ffIZtODLsiWfVuah7Oqtby2ey1PN2yHbCC7F/6BfRiaM4ji7IGUpOdTYpmUBH2U7K+j974dUL0FKt8M/azf17ID5ofc/u2HNZ2/1oz5/eSOH0/u+PEM+p8fs/ef/2T3M89Q9cx8dj3+N/z9+5N/3nnkX3AB2aOP87q7IiKSQhTCDpHPfAzKHcSg3EGcPPjkZvOq91fzUdVHrNm9hrW717Kuah1rd6/llR3vUR+sb2p3WNZhFA8upqT3KZT0LqEkp5ASfy6Dg+DfuxX2boXqzeHHltDPLR+Efkasp4k/I+oQ6IDmr/MKIC88LSM30W9Rt9F4jljehAkEa2upfnEJVfPns+tvf2PnQw+RNriQXkeOYOt7y/FlZ2FZWfiysrGsTHzZ2fiysrCs7NC8zKwDbbKzscxMXdVfREQ6RCEsgfIy8hjVfxSj+o9qNr0h2MDG6o3NRs7W7l7L4o8Xs6tuV1O7DF8Gh/c+nJL8Ekr6llBSfDwlvUsozi8mJz0HnIOanQeCWfUW2LuleVjb9TFULg0FOWLcljMjr0VYO3zrPnjro+ZhLXdgUp2/5svKIv+8c8k/71wC1XupfuF5qp6ZT/0rr7CtouKg1mnZ2fgyM0M/s7Kw7FCIC4W3rObTssOBLivzQLALB7pm7SPnZWWFwp5PV5YREUkGCmEeSPOlMSx/GMPyhzFh6IRm83bW7mwaMWt8fLDjA577+DmCLtjUblDuoFA46x3xGDSBAdkDYo/IBBpg3/bWw1r1Fti6EtYuoaR2F6x7qOU6svtGjaxFjq5FTMvp16POX/Pn5dL7wgvpfeGFVFRUMOH003G1tQRra5t+BmtqcbU1oZ91odfB2hpcTWO7GoK1dU1tmubV1RLct4/gjh24mppm63R1dQfV3wOBrnlgOxDswmEvM0boizGK1yz0VVcTrKlR2BMR6QIKYd1M36y+9M3qy/EDj282fX9gPx9Xfdw0atb4eGr1U+xrOHAOWW56LsX5xc3DWX4Jw/KHkdGrAHoVtNuHF59fxIQxn2olrG2G6q2w4a3Q85jnr/lCQS03xrdDo78xmtWn252/Zn4/lpuLLzexh2pdMHggkNXUEKyrI1hTE5pW00awiwxyEfOCNbUEd+46EPYaf3Yg7A0EVoafW1ZW1Mhe9oGwlxkj9DUeuo0n9DWOGmZlKeyJSMpSCOshMvwZlPYtpbRvabPpzrnQFwOiwtnSzUuZt2ZeUzuf+SjKK2oezsIBrU9Wn+br9KVDn6GhR3vqqkNhrOm8taiwVr05NMLW1vlr8YS13IGQmVwXXjWfD8vJwZeT2OvKuWAQV1fXPJg1jfA1D30r//0epUOLWozmNRvxawx7kQEyvM6DYZmZMUf2Wj10217oaxwZjFqnwp6IdDcKYT2cmVGQW0BBbgHjC8c3m7evfl+LQ5trq9byz43/ZH9wf1O7vpl9mwWzPfv2cETVEQzOG4y/vcOKmXmhR78j2m7XeP5aW2Ftd2VohK2189fSc+MLa3kDIS0zzncw+ZnPFwoj2dnQt2+bbWv696dfxKVZOsI5Fwp7rY3mRYe+uuaHeYO1Nbja5mGxfvfulkGwpuag+mfhkbdYAc2XlUXvqio2PDMfS08PPTIyDjxv7dHYJiOONlEP0tL0ZQ6RFKcQlsRy0nMY2W8kI/uNbDY9EAywce/GFtc8e2H9Czyx6gkA/vjkH0n3pXN4/uFNXwYo6V3C8N7DKe5dTG56Bw/VmYWudZZzGAwY0XbbYCDi/LXIwBbxLdHw+WvU7oq9jqw+sUNas7BWELrsRw86f607M7OmQJNIjWGvtdG8FodwI8/va+WwbkNVFWk7dlCzbRuuvr7Fg/oYo7idoNWglpEOcYY5S89otlyz1y3WETE/Kjj6t26lftOmFtvB71dYFEkQhbAU5Pf5GdprKEN7DeWMojOazdtVu4s5FXPoe0TfpkOcq3au4vmPnyfgAk3tBuYMbDqcGTmKVpBTcOj/YPv8B8ITx7TdtqEuxuha1CU9Nrwdvv7a3pbLmw9y+jd9ueCoPQHY/bfQYdK0TPCnh577I56nZYSnZYSnZR54npYZNT39QNvI5Xxp3e5cuJ6iMeyRlUVnxueKiopmF2iO5JwLBbL99bj6/U3BrEVg278/ZoiLOX9/HG0aH3X7CVbvbXcbNDQcdP39gdWxZpjFPboXGR594TYtwmRkeMyIen0oo4266LL0QAph0kyfrD4MzxpOeVl5s+n1gXrW71nf7JIaa3evZd6aeVTXVze1y0nLobh3cYuANix/GJn+BBwiTMuE3kWhR3vqqsNfNIj8skHzLx7kV22Amv9AYD807A/9DBzctxjbZjHCWVSgaxEEM2IHuujA11p4bGtb4fDob9gL9TWheTqHqomZhW51lZEBdN9r67lgENfQcCCoNQW9A8GN+nqCUUGO+npWvPtvPlV6ROthMDo0xgiDwZpaXNWe9sNiINB+MR3l88V36LjFyGA6+du3s/Efi7C0tNAjPS10uDgtvem1pbWcht/fepvw67anRb3Wf8xSjkKYxCXdn87wPsMZ3md4s+nOObbVbGtxzbO3N7/NM2ueaWrnMx9D8oY0O7TZ+Oib2bdr/vFpPH/tsOGtNnk91miIc6FDpIG6cCirD43ANT4P1IV/7o8Kb1GPpun1B8Jd4/OGqHUEItrWVsXeVuQysb70cBBOB3g5/ML8MQJfVPiLa7Qw1jLthce2QmfEuvSh1Yz5fBFhsWNqc3Loc5DnAwKhvxPnwAWB8M9WXruG+lBYrKsLB7a6A2Fx//6In22Euf3hQNkUMBtCo5MNDU2vQ4/IaXW42r0EqwOheQ2hNln7atj74SpcIAANAVwggAv/JBBsr/LOEx3M0iNCX6vT/M3DYawQ2UawzF6zlp2fbD64EJmeHvo2eeTrxvk6jB0XhTA5JGbGgJwBDMgZwLjCcc3m7avfx0dVH7X4csDrm16nLmJ0qXdm75bXPOtdwpC8IaT5usGvqBn400KP7joK4lzz4NYiJO5vP/A17Gf1f96ntHhoy+VaDYnhcFlX3cq2Itq5RIx+xBsE2x8tLFm/ARpepGWAIPy69VDR/HV7bSLatdsmcvtttWmcRhxtYm/7lLpaeDM9xjIRNbVVVwdY+NHpDEgPPzqJc0AQnLPwW2Dhac1fO9IAP86l4fCHH2ng/Dh8OOfHOR8OHzhf6HnQh3MG+MLr8YXfWgut34XXHwzgggEI1uGCDlcPrs6FngdcaJlAEBd0EAiGnkc8aAiGgmUgAMHmX3rKBz7pvLerufTmATJWiCTNT/tBs3Fa1Ehk43x/66OV7QVL344diao+Lt3gE06SVU56Dkf1O4qj+h3VbHrQBdm0d1OLLwYsqVzCk6ufbGqX5kvj8F6HtwhnxfnF5GUk1+UqDplZKFgc4rdCK2sqKD29vHP6FC0YaGW0sK3AF88oY3TojB5l3A/790FgVyvLhdoNC9RDpS90niAW+mm+0HvbNM2iXsdq4wunjMjXEW2bTbM42oRf+3xgaW23iVxvu218zba/bdMnDB4y5BDX20Zdh/yeNr4mjjZR+6Gd9+Ltt99izHHHhkaUgw2hi1sHQw9r/Bmob5rW9AjUh36vgxHzmpZtua7QtEB4uVjraoh/XQf5n5qm7BwZ8mKFyqCFwmezMAgOP5AWESpDgbMpWIan4awpZIaWD4RGQYP1OFd7INMHLBQqHeFQSUS4DP0k6MKB0h0IloFQsIz1RfqOyDv9FLjkkkNbySFQCJMu13hockjeEE4bclqzebvrdrcYOVu9azUV6ytocAdOOh6YHfpiQPT5ZwW5Bfga/6GW7sXnB182pGd73ZOYXmzjxPxU8J+KCganaP1VH+6D4lO97kbHBIOhINZmoGtoEegsWB8KluHX7727jKNHjogKh43hsrV1RYXPQET7FoGxo+uKCq3tjLI2DsoSHRaDFh6ktabRxabwGfF6Z/G2LtldrVEIk26ld2ZvjhtwHMcNOK7Z9PpgPZV7Kltc82z+mvnsqd/T1C47LZvi/OID4Swc0A7PP5ystMReOkFEpMv4fIAvdFj9EGzblAWjyjulSwkRDLYcSYwIdBYxWtnxcNjA6soahnlYnkKY9AjpvvSmUBXJOcf22u0twtm7W99lwdoFuPBYtWEMzhvc4m4BJb1LOCzrMJ1AKiLSHfl84MsAOv5lk3jsrq5IyHrjpRAmPZqZ0T+7P/2z+3PioBObzatpqAndbzMinK3bvY6lnyylNnDgFjv5GfmhkbP8EgK7A2x4fwNZ/iyy0rLITss+8DNiWuP0DF+GApyIiBwUhTBJWtlp2Yw4bAQjDmt+hf6gC7J57+YW1zx7deOrbK3Zyrw35rWyxpYMaxbSGsNZ4yPbn90szEW3yU7LbmoTuUxkm0x/ps5zExFJQgphknJ85qMwr5DCvEJOGXJKs3mLXljEuFPGUdNQQ01DDbUNtdQGag88bwg/j5rW+Dpymaq6KjY3bG6xnmAHv84PtBiZaxbm/Flkp2e3mBY9atc4LSct50DoCy+T6c9s/z6hIiLSqRTCRCKkWzq9M3vTO7N3QtbvnKMh2EBNoIaa+lCYiwx2Tc+jptU21LKvYV9TmGucVl1fzbaabc1DYqCGhmDHb1+T6c/E7/z0erxXmyN3LQKeP6v5yF6MaY2vu8V130REugn9iyjShcyMdH866f508jPyE7ad+mA9dQ11BwJdoPmoXVOgiwhutQ21rP5oNf0K+jWbVtNQw47aHS1G//YH93e4X+m+9GaHaZuddxd5WDY8utdiWlrzQ7WRIbHxZ7qvE6/UKSKSQAphIkko3ZdOekZ6hy9qW7GngvJTy+NqGwgG4jos29roXvRh2qq6qhajf5FfoIhXmqW1G+ZiHapdX7WeLSu3kO5LJ82XFgrLvnQyfBlNz5s9oqeFX6f50nQOn4jERSFMRA6K3+cn15dLbnribuUUdMEWh2AjR+hiHbZtCoFRy9TU17CtZluLwFjbUNt0KZMnXnuiU/qdZmnNQ1qcIS7Nl9ZsWoY/46CXb1q2jcCosCjiLYUwEem2fOYjJz2HnPSchG3DOUddoI7FLy7mpFNOoj5QT30w4tHO6/2B/dQH62kINsTVvvH1/uB+6gP11DbUttv+YA79xsNv/qZg5gKOnMdz4gtxUSN/sdrEu3z0yGOLZX3p+tKIJC2FMBFJaWahy4zk+nPpn93f6+7E5Jwj4AItQ190YIsj9EXPawyP69avY2DhwFZDZnV9ddO81gLn/sD+plHFzuQzX4dCYHSIiw6B0aFvXdU6PvngE3zmazqc7Dc/fvPj8x147jd/aJ7vwPPG9mkW+tliHRFtI9fZ2L6xjUYlU5NCmIhIN2dmpFkaab40stMSc+/Nin0VlJ9SfsjrCQQDLQJcrNAXMzBGjPy1FTDbCoE1DTVU7a9qMT86tAaib4D9+iGXfsiawp4vKrS1EvyazY8OfJHtGwNfdCD0+dm8fTNL/rmk2XZjte/MbbbZPrr+GMs3tk+GC2UrhImISKfx+0IflFl073u1BoIBGlwomFW8VMH4U8YTdEECwQABFyDogjS4BoLBIAF3YFrABZq1adE+ok3M9hHz4m7fuP5gK+0b20T0dX9gf7u1NAQbqKmrYeXHK1ss39jmYK5r2FUMaz+0RYXI6NHLkoYSyin3rAaFMBERSTl+nx8/fjL9meT587rtoehEq6iooLy8vNX5jYfCW4TAqBDaaig9mBAbI7QeTIiNZ5vpAW8vaaMQJiIiIjE1HgoHyPAn5ibaXqqoqPB0+zoTUERERMQDCmEiIiIiHlAIExEREfGAQpiIiIiIBxIawsxskpmtNLPVZjYtxnwzs5nh+e+a2ZhE9kdERESku0hYCDMzPzALOB8YCXzBzEZGNTsfKAs/rgL+kKj+iIiIiHQniRwJGwesds6tcc7tB2YDU6LaTAEedCGvAX3MrDCBfRIRERHpFhIZwoYA6yNeV4andbSNiIiISNJJ5MVaY93UKfrOrvG0wcyuInS4koKCgi65uFp1dbXnF3Hzimqv8Lobnknl+lO5dkjt+lV7hdfd8IzX9ScyhFUCQyNeFwEbD6INzrl7gHsAxo4d69q6xUJnae9WDslMtZd73Q3PpHL9qVw7pHb9qr3c6254xuv6E3k48k2gzMxKzCwDuBx4OqrN08DU8LckxwO7nXObEtgnERERkW4hYSNhzrkGM/sWsBDwA/c755ab2TfC8+8G5gOTgdXAPuCrieqPiIiISHeS0Bt4O+fmEwpakdPujnjugG8msg8iIiIi3ZGFclDPYWZbgY+6YFP9gW1dsJ3uSLWnrlSuP5Vrh9SuX7Wnrq6o/3Dn3IBYM3pcCOsqZrbUOTfW6354QbWnZu2Q2vWncu2Q2vWr9tSsHbyvX/eOFBEREfGAQpiIiIiIBxTCWneP1x3wkGpPXalcfyrXDqldv2pPXZ7Wr3PCRERERDygkTARERERD6R0CDOzSWa20sxWm9m0GPPNzGaG579rZmO86GeixFF/uZntNrNl4cfNXvQzEczsfjPbYmbvtTI/afd9HLUn834famYvmNn7ZrbczL4bo01S7vs4a0/mfZ9lZm+Y2Tvh+m+L0SZZ9308tSftvgcwM7+Z/cvM5sWY591+d86l5IPQVfw/BIYDGcA7wMioNpOBZwndaHw88LrX/e7i+suBeV73NUH1nwGMAd5rZX4y7/v2ak/m/V4IjAk/7wX8J1X+7uOsPZn3vQF54efpwOvA+BTZ9/HUnrT7Plzf94GHY9Xo5X5P5ZGwccBq59wa59x+YDYwJarNFOBBF/Ia0MfMCru6owkST/1Jyzm3BNjRRpOk3fdx1J60nHObnHNvh5/vAd4HhkQ1S8p9H2ftSSu8P6vDL9PDj+iTopN138dTe9IysyLgAuC+Vpp4tt9TOYQNAdZHvK6k5T9I8bTpqeKt7eTwEPazZjaqa7rWLSTzvo9H0u93MysGjic0KhAp6fd9G7VDEu/78CGpZcAWYJFzLmX2fRy1Q/Lu+98APwCCrcz3bL+ncgizGNOi/2cQT5ueKp7a3iZ0u4XjgN8BTyW6U91IMu/79iT9fjezPOAJ4HvOuaro2TEWSZp9307tSb3vnXMB59xooAgYZ2ZHRzVJ2n0fR+1Jue/N7NPAFufcW201izGtS/Z7KoewSmBoxOsiYONBtOmp2q3NOVfVOITtQjdjTzez/l3XRU8l875vU7LvdzNLJxRCHnLOzYnRJGn3fXu1J/u+b+Sc2wVUAJOiZiXtvm/UWu1JvO9PBS4ys3WETrs508z+GtXGs/2eyiHsTaDMzErMLAO4HHg6qs3TwNTwNyfGA7udc5u6uqMJ0m79ZjbIzCz8fByh35ftXd5TbyTzvm9TMu/3cF1/At53zs1opVlS7vt4ak/yfT/AzPqEn2cDZwMfRDVL1n3fbu3Juu+dcz90zhU554oJfc4975z7r6hmnu33tK7YSHfknGsws28BCwl9U/B+59xyM/tGeP7dwHxC35pYDewDvupVfztbnPV/DrjGzBqAGuByF/4qSU9nZo8Q+jZQfzOrBG4hdLJq0u/7OGpP2v1O6H/FXwb+HT4/BuBHwDBI+n0fT+3JvO8LgQfMzE8oYDzmnJuXIv/mx1N7Mu/7FrrLftcV80VEREQ8kMqHI0VEREQ8oxAmIiIi4gGFMBEREREPKISJiIiIeEAhTERERMQDCmEi0uOZWcDMlkU8pnXiuovN7L3OWp+ISKOUvU6YiCSVmvAtWUREegyNhIlI0jKzdWb2v2b2RvhRGp5+uJktNrN3wz+HhacXmNmT4ZsYv2Nmp4RX5Teze81suZn9I3zVcczsO2a2Irye2R6VKSI9lEKYiCSD7KjDkZdFzKtyzo0D7gJ+E552F/Cgc+5Y4CFgZnj6TODF8E2MxwDLw9PLgFnOuVHALuCz4enTgOPD6/lGYkoTkWSlK+aLSI9nZtXOubwY09cBZzrn1oRvXv2Jc66fmW0DCp1z9eHpm5xz/c1sK1DknKuLWEcxsMg5VxZ+fROQ7pz7f2a2AKgGngKearwBsohIPDQSJiLJzrXyvLU2sdRFPA9w4HzaC4BZwAnAW2am82xFJG4KYSKS7C6L+PnP8PNXgcvDz78EvBx+vhi4BsDM/GaW39pKzcwHDHXOvQD8AOgDtBiNExFpjf7XJiLJINvMlkW8XuCca7xMRaaZvU7oP51fCE/7DnC/md0IbAW+Gp7+XeAeM/tvQiNe1wCbWtmmH/irmfUGDLjTOberk+oRkRSgc8JEJGmFzwkb65zb5nVfRESi6XCkiIiIiAc0EiYiIiLiAY2EiYiIiHhAIUxERETEAwphIiIiIh5QCBMRERHxgEKYiIiIiAcUwkREREQ88P8BfcXoU/ajaWoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a list to store loss history for each learning rate\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "loss_history = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    # Create an instance of the neural network\n",
    "    net = Net()\n",
    "\n",
    "    # Define the loss function and optimizer with the current learning rate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 5\n",
    "    train_loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss / (i+1):.4f}')\n",
    "        train_loss_history.append(running_loss / (i+1))\n",
    "\n",
    "    loss_history.append(train_loss_history)\n",
    "\n",
    "# Plot the loss curves for each learning rate\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    plt.plot(range(num_epochs), loss_history[i], label=f'LR={lr}')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss with Different Learning Rates')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập train/test tỉ lệ 80/20, tính các chỉ số MSE, RSME, MAE, MAPE trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1792x28 and 2x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bc49d9700792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mall_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-29eeda5fd4ea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Sigmoid activation for the hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Sigmoid activation for the output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1792x28 and 2x2)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "total_size = len(mnist_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(mnist_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define and train your neural network (you can use the previous code)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(predicted.numpy())\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(all_labels, all_predictions)\n",
    "\n",
    "# Calculate the Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(all_labels, all_predictions)\n",
    "\n",
    "# Calculate the Mean Absolute Percentage Error (MAPE)\n",
    "mape = np.mean(np.abs(np.array(all_labels) - np.array(all_predictions)) / np.array(all_labels)) * 100\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape:.4f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.199\n",
      "Root Mean Squared Error (RMSE): 1.094988584415381\n",
      "Mean Absolute Error (MAE): 0.2494\n",
      "Mean Absolute Percentage Error (MAPE): nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-380c0a161231>:28: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = np.mean(np.abs((np.array(true_labels) - np.array(predicted_labels)) / np.array(true_labels))) * 100\n",
      "<ipython-input-9-380c0a161231>:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mape = np.mean(np.abs((np.array(true_labels) - np.array(predicted_labels)) / np.array(true_labels))) * 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "total_size = len(train_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "# Evaluation on the test set\n",
    "net.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_labels.extend(labels.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "\n",
    "# Calculate MSE, RMSE, MAE, and MAPE\n",
    "mse = mean_squared_error(true_labels, predicted_labels)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_labels, predicted_labels)\n",
    "mape = np.mean(np.abs((np.array(true_labels) - np.array(predicted_labels)) / np.array(true_labels))) * 100\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function uses the exponential function with the base 'e' (the natural logarithm base) mainly because of the properties of the 'e' exponential function that make it suitable and reasonable for multi-class classification problems and probability representation. Here are some reasons why 'e' is typically used in softmax:\n",
    "\n",
    "1. **Probability Property:** The softmax function is used to represent the probabilities of different classes. The 'e' exponential function ensures that the output of softmax is always within the range [0, 1], which is a reasonable probability range.\n",
    "\n",
    "2. **Ability to Distinguish Differences:** The 'e' exponential function has the property of rapid increase, which creates differences between input values. When one input value is significantly higher than the others, its corresponding output from softmax will also be higher, resulting in a higher probability. This allows the model to distinguish between classes effectively.\n",
    "\n",
    "3. **Related to Probability and Nature:** The 'e' exponential function is a natural exponentiation function that frequently appears in probability and natural processes. For example, the Poisson distribution and the standard normal distribution are based on the 'e' exponential function. Using 'e' ensures a natural connection of softmax probability results to probability theory and statistics.\n",
    "\n",
    "4. **Ease of Derivative Calculation:** The 'e' exponential function has an easily computable derivative. This is crucial when training models using gradient descent algorithms to adjust parameters.\n",
    "\n",
    "In summary, using the 'e' exponential function in the softmax function is a natural and reasonable choice for representing probabilities and making multi-class classification models work effectively and naturally. Question is why not using other constants like 2, 3, or 4, the primary reason is that these constants do not possess the properties that 'e' offers, especially in the context of probability representation. Other constants would not provide the same behavior and mathematical properties that make softmax suitable for classification problems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
